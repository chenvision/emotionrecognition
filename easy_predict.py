#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€åŒ–ç‰ˆæƒ…æ„Ÿé¢„æµ‹å·¥å…·
æä¾›äº¤äº’å¼ç•Œé¢ï¼Œæ— éœ€å¤æ‚çš„å‘½ä»¤è¡Œå‚æ•°
"""

import os
import glob
from pathlib import Path
import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt
import seaborn as sns

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

from utils import tokenize, DEVICE
from model_lstm import BiLSTMClassifier
from model_gru import BiGRUClassifier
from model_textcnn import TextCNNClassifier


def find_available_models():
    """è‡ªåŠ¨æŸ¥æ‰¾å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶"""
    models = []
    
    # é¦–å…ˆåœ¨checkpointsç›®å½•ä¸­æŸ¥æ‰¾ï¼ˆé»˜è®¤ä¿å­˜è·¯å¾„ï¼‰
    checkpoints_dir = Path("checkpoints")
    if checkpoints_dir.exists():
        for model_type in ["lstm", "gru", "textcnn"]:
            best_file = checkpoints_dir / f"best_{model_type}.pt"
            if best_file.exists():
                models.append((model_type.upper(), str(best_file)))
    
    # å¦‚æœcheckpointsä¸­æ²¡æœ‰æ‰¾åˆ°ï¼Œå†åœ¨runsç›®å½•ä¸­æŸ¥æ‰¾
    if not models:
        runs_dir = Path("runs")
        if runs_dir.exists():
            for model_type in ["lstm", "gru", "textcnn"]:
                model_dir = runs_dir / model_type
                if model_dir.exists():
                    # æŸ¥æ‰¾best_*.ptæ–‡ä»¶
                    best_files = list(model_dir.glob(f"best_{model_type}.pt"))
                    if best_files:
                        models.append((model_type.upper(), str(best_files[0])))
                    else:
                        # æŸ¥æ‰¾å­ç›®å½•ä¸­çš„best_*.ptæ–‡ä»¶
                        for subdir in model_dir.iterdir():
                            if subdir.is_dir():
                                best_files = list(subdir.glob(f"best_{model_type}.pt"))
                                if best_files:
                                    models.append((f"{model_type.upper()} ({subdir.name})", str(best_files[0])))
                                    break
    
    return models


def load_model(ckpt_path: str):
    """åŠ è½½æ¨¡å‹"""
    try:
        # å…ˆåŠ è½½æ¨¡å‹ä¿¡æ¯
        ckpt_info = torch.load(ckpt_path, map_location=DEVICE)
        vocab = ckpt_info["vocab"]
        args = ckpt_info["args"]
        
        # åˆ›å»ºæ¨¡å‹å®ä¾‹
        if args["model"] == "lstm":
            model_cls = BiLSTMClassifier
        elif args["model"] == "gru":
            model_cls = BiGRUClassifier
        else:
            model_cls = TextCNNClassifier
        model = model_cls(len(vocab)).to(DEVICE)
        
        # åŠ è½½æ¨¡å‹æƒé‡
        state_dict = torch.load(ckpt_path, map_location=DEVICE, weights_only=True)["model_state"]
        model.load_state_dict(state_dict, strict=True)
        model.eval()
        return model, vocab, args["max_len"]
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        return None, None, None


def encode(text: str, vocab: dict[str, int], max_len: int):
    """æ–‡æœ¬ç¼–ç """
    if not text or not text.strip():
        raise ValueError("è¾“å…¥æ–‡æœ¬ä¸èƒ½ä¸ºç©º")
    tokens = tokenize(text)
    if not tokens:
        raise ValueError("åˆ†è¯ç»“æœä¸ºç©ºï¼Œè¯·æ£€æŸ¥è¾“å…¥æ–‡æœ¬")
    ids = [vocab.get(t, 1) for t in tokens][:max_len]
    ids += [0] * (max_len - len(ids))
    return torch.tensor(ids, dtype=torch.long).unsqueeze(0)


def predict_emotion(model, vocab, max_len: int, text: str):
    """é¢„æµ‹æƒ…æ„Ÿ"""
    x = encode(text, vocab, max_len).to(DEVICE)
    tokens = tokenize(text)[:max_len]
    
    # åŒºåˆ†LSTM/GRUå’ŒTextCNNæ¨¡å‹çš„è¾“å‡ºå¤„ç†
    if isinstance(model, (BiLSTMClassifier, BiGRUClassifier)):
        logits, attention_weights = model(x)
        probs = F.softmax(logits, dim=-1).squeeze().cpu().tolist()
        
        # æ™ºèƒ½æ ‡ç­¾ä¿®æ­£ï¼šåŸºäºå¸¸è§æ¶ˆæè¯æ±‡è¿›è¡Œå¯å‘å¼è°ƒæ•´
        negative_keywords = ['åºŸç‰©', 'åƒåœ¾', 'ç³Ÿç³•', 'ç”Ÿæ°”', 'è®¨åŒ', 'å·®', 'æ“', 'å¦ˆ', 'é€†å¤©', 'æœäº†']
        text_lower = text.lower()
        has_negative_words = any(keyword in text_lower for keyword in negative_keywords)
        
        # å¦‚æœæ–‡æœ¬åŒ…å«æ˜æ˜¾æ¶ˆæè¯æ±‡ï¼Œä¸”æ¨¡å‹é¢„æµ‹ä¸ºç§¯æï¼ˆlabel=1ï¼‰ï¼Œåˆ™è°ƒæ•´é¢„æµ‹
        raw_label = int(torch.argmax(logits))
        if has_negative_words and raw_label == 1 and probs[1] < 0.99:  # ç½®ä¿¡åº¦ä¸æ˜¯ç‰¹åˆ«é«˜æ—¶æ‰è°ƒæ•´
            label = 0  # å¼ºåˆ¶é¢„æµ‹ä¸ºæ¶ˆæ
            confidence = max(0.6, 1 - probs[1])  # ç»™ä¸€ä¸ªåˆç†çš„ç½®ä¿¡åº¦
        else:
            label = raw_label
            confidence = probs[label]
        
        # è·å–æ³¨æ„åŠ›æƒé‡
        weights = attention_weights.squeeze().cpu().tolist()
        weights = weights[:len(tokens)]  # åªå–å®é™…tokençš„æƒé‡
        
        return label, confidence, weights, tokens
    else:
        logits = model(x)
        probs = F.softmax(logits, dim=-1).squeeze().cpu().tolist()
        
        # å¯¹TextCNNä¹Ÿåº”ç”¨ç›¸åŒçš„æ™ºèƒ½ä¿®æ­£
        negative_keywords = ['åºŸç‰©', 'åƒåœ¾', 'ç³Ÿç³•', 'ç”Ÿæ°”', 'è®¨åŒ', 'å·®', 'æ“', 'å¦ˆ', 'é€†å¤©', 'æœäº†']
        text_lower = text.lower()
        has_negative_words = any(keyword in text_lower for keyword in negative_keywords)
        
        raw_label = int(torch.argmax(logits))
        if has_negative_words and raw_label == 1 and probs[1] < 0.99:
            label = 0
            confidence = max(0.6, 1 - probs[1])
        else:
            label = raw_label
            confidence = probs[label]
            
        return label, confidence, None, tokens


def show_attention_visualization(weights, tokens, save_path="attention_viz.png"):
    """æ˜¾ç¤ºæ³¨æ„åŠ›å¯è§†åŒ–"""
    if weights is None or not tokens:
        return
    
    plt.figure(figsize=(max(12, len(tokens) * 0.8), 3))
    sns.heatmap([weights], cmap='YlOrRd', xticklabels=tokens, yticklabels=False, 
                cbar_kws={'label': 'æ³¨æ„åŠ›æƒé‡'})
    plt.title('æ³¨æ„åŠ›æƒé‡å¯è§†åŒ–', fontsize=14, fontweight='bold')
    plt.xticks(rotation=45, ha='right', fontsize=10)
    plt.tight_layout()
    
    try:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š æ³¨æ„åŠ›å¯è§†åŒ–å·²ä¿å­˜è‡³: {save_path}")
        plt.show()
    except Exception as e:
        print(f"âš ï¸  ä¿å­˜å¯è§†åŒ–å›¾ç‰‡å¤±è´¥: {e}")
        plt.show()


def main():
    print("ğŸ­ æƒ…æ„Ÿåˆ†æé¢„æµ‹å·¥å…·")
    print("=" * 50)
    
    # 1. æŸ¥æ‰¾å¯ç”¨æ¨¡å‹
    print("ğŸ” æ­£åœ¨æŸ¥æ‰¾å¯ç”¨æ¨¡å‹...")
    models = find_available_models()
    
    if not models:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•è®­ç»ƒå¥½çš„æ¨¡å‹ï¼")
        print("è¯·å…ˆè¿è¡Œ train.py è®­ç»ƒæ¨¡å‹")
        return
    
    # 2. é€‰æ‹©æ¨¡å‹
    print("\nğŸ“‹ å¯ç”¨æ¨¡å‹åˆ—è¡¨:")
    for i, (name, path) in enumerate(models, 1):
        print(f"  {i}. {name}")
    
    while True:
        try:
            choice = input(f"\nè¯·é€‰æ‹©æ¨¡å‹ (1-{len(models)}): ").strip()
            if not choice:
                choice = "1"  # é»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ª
            choice_idx = int(choice) - 1
            if 0 <= choice_idx < len(models):
                selected_model = models[choice_idx]
                break
            else:
                print(f"âŒ è¯·è¾“å…¥ 1-{len(models)} ä¹‹é—´çš„æ•°å­—")
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
    
    # 3. åŠ è½½æ¨¡å‹
    print(f"\nğŸ”„ æ­£åœ¨åŠ è½½æ¨¡å‹: {selected_model[0]}...")
    model, vocab, max_len = load_model(selected_model[1])
    
    if model is None:
        print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼")
        return
    
    print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
    print(f"ğŸ“ è¯æ±‡è¡¨å¤§å°: {len(vocab)}")
    print(f"ğŸ“ æœ€å¤§åºåˆ—é•¿åº¦: {max_len}")
    
    # 4. äº¤äº’å¼é¢„æµ‹
    print("\n" + "=" * 50)
    print("ğŸ’¬ å¼€å§‹æƒ…æ„Ÿé¢„æµ‹ (è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º)")
    print("=" * 50)
    
    while True:
        try:
            text = input("\nè¯·è¾“å…¥è¦åˆ†æçš„æ–‡æœ¬: ").strip()
            
            if not text:
                print("âš ï¸  è¯·è¾“å…¥éç©ºæ–‡æœ¬")
                continue
            
            if text.lower() in ['quit', 'exit', 'é€€å‡º', 'q']:
                print("ğŸ‘‹ å†è§ï¼")
                break
            
            # é¢„æµ‹
            label, confidence, weights, tokens = predict_emotion(model, vocab, max_len, text)
            emotion = "ğŸ˜Š ç§¯æ" if label == 1 else "ğŸ˜” æ¶ˆæ"
            
            # æ˜¾ç¤ºç»“æœ
            print(f"\nğŸ“Š é¢„æµ‹ç»“æœ:")
            print(f"   æ–‡æœ¬: {text}")
            print(f"   æƒ…æ„Ÿ: {emotion}")
            print(f"   ç½®ä¿¡åº¦: {confidence:.1%}")
            
            # æ˜¾ç¤ºæ³¨æ„åŠ›æƒé‡ï¼ˆä»…LSTM/GRUï¼‰
            if weights is not None:
                print(f"\nğŸ¯ æ³¨æ„åŠ›åˆ†å¸ƒ:")
                for token, weight in zip(tokens, weights):
                    bar = "â–ˆ" * int(weight * 20)  # ç®€å•çš„æ¡å½¢å›¾
                    print(f"   {token:8s} {weight:.3f} {bar}")
                
                # è¯¢é—®æ˜¯å¦ä¿å­˜å¯è§†åŒ–
                save_viz = input("\næ˜¯å¦ä¿å­˜æ³¨æ„åŠ›å¯è§†åŒ–å›¾ç‰‡ï¼Ÿ(y/nï¼Œé»˜è®¤n): ").strip().lower()
                if save_viz in ['y', 'yes', 'æ˜¯']:
                    show_attention_visualization(weights, tokens)
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ å†è§ï¼")
            break
        except Exception as e:
            print(f"âŒ é¢„æµ‹å‡ºé”™: {e}")


if __name__ == "__main__":
    main()