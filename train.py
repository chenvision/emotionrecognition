"""æƒ…æ„Ÿåˆ†ç±»æ¨¡å‹è®­ç»ƒè„šæœ¬ - æ”¯æŒLSTMã€GRUã€TextCNNä¸‰ç§æ¨¡å‹"""
from __future__ import annotations  # å…è®¸åœ¨æ³¨è§£ä¸­ä½¿ç”¨ç±»å‹æç¤º
import argparse  # å‘½ä»¤è¡Œå‚æ•°è§£æå™¨
import torch
from torch import nn, optim  # ç¥ç»ç½‘ç»œå’Œä¼˜åŒ–å™¨
from torch.nn import functional as F
from tqdm import tqdm  # è¿›åº¦æ¡
from pathlib import Path  # è·¯å¾„æ“ä½œ
from quick_test import quick_test, load_model

from data_loader import get_dataloaders  # æ•°æ®åŠ è½½å™¨
from utils import compute_metrics, DEVICE
from model_lstm import BiLSTMClassifier
from model_gru import BiGRUClassifier
from model_textcnn import TextCNNClassifier

# ======================================================================
# Focal Loss å®ç°
# ======================================================================

class FocalLoss(nn.Module):
    """Focal Losså®ç°ï¼Œç”¨äºå¤„ç†ç±»åˆ«ä¸å¹³è¡¡å’Œéš¾åˆ†æ ·æœ¬
    
    Args:
        alpha: ç±»åˆ«æƒé‡ï¼Œå¯ä»¥æ˜¯floatæˆ–tensor
        gamma: èšç„¦å‚æ•°ï¼Œgammaè¶Šå¤§è¶Šå…³æ³¨éš¾åˆ†æ ·æœ¬
        reduction: æŸå¤±èšåˆæ–¹å¼
    """
    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction
    
    def forward(self, inputs, targets):
        # è®¡ç®—äº¤å‰ç†µæŸå¤±
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')
        
        # è®¡ç®—æ¦‚ç‡
        pt = torch.exp(-ce_loss)
        
        # è®¡ç®—focalæƒé‡
        focal_weight = (1 - pt) ** self.gamma
        
        # åº”ç”¨alphaæƒé‡
        if self.alpha is not None:
            if isinstance(self.alpha, (float, int)):
                alpha_t = self.alpha
            else:
                alpha_t = self.alpha.gather(0, targets)
            focal_loss = alpha_t * focal_weight * ce_loss
        else:
            focal_loss = focal_weight * ce_loss
        
        # èšåˆæŸå¤±
        if self.reduction == 'mean':
            return focal_loss.mean()
        elif self.reduction == 'sum':
            return focal_loss.sum()
        else:
            return focal_loss

# ======================================================================
# è®­ç»ƒå’Œè¯„ä¼°å‡½æ•°
# ======================================================================

def train_one_epoch(model, loader, criterion, optimizer):
    """è®­ç»ƒä¸€ä¸ªepoch
    
    Args:
        model: ç¥ç»ç½‘ç»œæ¨¡å‹
        loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        criterion: æŸå¤±å‡½æ•°
        optimizer: ä¼˜åŒ–å™¨
    
    Returns:
        float: å¹³å‡è®­ç»ƒæŸå¤±
    """
    model.train()  # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
    total_loss = 0
    
    for x, y in loader:
        # å°†æ•°æ®ç§»åŠ¨åˆ°GPU/CPU
        x, y = x.to(DEVICE), y.to(DEVICE)
        
        # æ¢¯åº¦æ¸…é›¶
        optimizer.zero_grad()
        
        # å‰å‘ä¼ æ’­ï¼ˆå¿½ç•¥æ³¨æ„åŠ›æƒé‡ï¼‰
        logits, _ = model(x)
        
        # è®¡ç®—æŸå¤±
        loss = criterion(logits, y)
        
        # åå‘ä¼ æ’­
        loss.backward()
        
        # å‚æ•°æ›´æ–°
        optimizer.step()
        
        # ç´¯ç§¯æŸå¤±
        total_loss += loss.item() * y.size(0)
    
    return total_loss / len(loader.dataset)


@torch.no_grad()
def evaluate(model, loader, criterion):
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½
    
    Args:
        model: ç¥ç»ç½‘ç»œæ¨¡å‹
        loader: éªŒè¯/æµ‹è¯•æ•°æ®åŠ è½½å™¨
        criterion: æŸå¤±å‡½æ•°
    
    Returns:
        dict: åŒ…å«æŸå¤±ã€å‡†ç¡®ç‡ã€F1åˆ†æ•°ç­‰æŒ‡æ ‡çš„å­—å…¸
    """
    model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    total_loss = 0
    preds, labels = [], []
    attention_weights_list = []
    
    for x, y in loader:
        # å°†æ•°æ®ç§»åŠ¨åˆ°GPU/CPU
        x, y = x.to(DEVICE), y.to(DEVICE)
        
        # å‰å‘ä¼ æ’­
        logits, attention_weights = model(x)
        
        # è®¡ç®—æŸå¤±
        loss = criterion(logits, y)
        total_loss += loss.item() * y.size(0)
        
        # æ”¶é›†é¢„æµ‹ç»“æœå’ŒçœŸå®æ ‡ç­¾
        preds.extend(torch.argmax(logits, dim=-1).cpu().tolist())
        labels.extend(y.cpu().tolist())
        
        # ä¿å­˜æ³¨æ„åŠ›æƒé‡ç”¨äºå¯è§†åŒ–
        attention_weights_list.append(attention_weights.cpu())
    
    # è®¡ç®—å„ç§è¯„ä¼°æŒ‡æ ‡
    metrics = compute_metrics(preds, labels)
    metrics["loss"] = total_loss / len(loader.dataset)
    metrics["attention_weights"] = torch.cat(attention_weights_list, dim=0)
    
    return metrics


# ======================================================================
# ä¸»è®­ç»ƒå‡½æ•°
# ======================================================================

def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    # è®¾ç½®å‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="æƒ…æ„Ÿåˆ†ç±»æ¨¡å‹è®­ç»ƒ")
    
    # æ•°æ®ç›¸å…³å‚æ•°
    parser.add_argument("--data_dir", type=str, default="data", 
                       help="è®­ç»ƒæ•°æ®ç›®å½•")
    parser.add_argument("--max_len", type=int, default=128, 
                       help="æ–‡æœ¬æœ€å¤§é•¿åº¦")
    
    # æ¨¡å‹ç›¸å…³å‚æ•°
    parser.add_argument("--model", choices=["lstm", "gru", "textcnn"], 
                       default="lstm", help="æ¨¡å‹ç±»å‹")
    
    # è®­ç»ƒç›¸å…³å‚æ•°
    parser.add_argument("--epochs", type=int, default=30, 
                       help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--batch_size", type=int, default=32, 
                       help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--lr", type=float, default=5e-4, 
                       help="å­¦ä¹ ç‡")
    parser.add_argument("--weight_decay", type=float, default=1e-4, 
                       help="L2æ­£åˆ™åŒ–ç³»æ•°")
    parser.add_argument("--patience", type=int, default=7, 
                       help="æ—©åœè€å¿ƒå€¼ï¼ˆè¿ç»­å¤šå°‘è½®ä¸æ”¹å–„å°±åœæ­¢ï¼‰")
    parser.add_argument("--min_improvement", type=float, default=1e-4, 
                       help="F1åˆ†æ•°æ”¹å–„çš„æœ€å°é˜ˆå€¼")
    parser.add_argument("--resume_best", action="store_true", 
                       help="è‡ªåŠ¨åŸºäºå·²æœ‰æœ€ä½³æ¨¡å‹çš„F1åˆ†æ•°ä½œä¸ºåŸºå‡†ç»§ç»­è®­ç»ƒ")
    parser.add_argument("--overwrite", action="store_true", 
                       help="å¼ºåˆ¶è¦†ç›–å·²æœ‰æ¨¡å‹ï¼Œä»0å¼€å§‹è®¡ç®—F1åŸºå‡†")
    
    # æŸå¤±å‡½æ•°ç›¸å…³å‚æ•°
    parser.add_argument("--loss_type", choices=["crossentropy", "focal"], 
                       default="crossentropy", help="æŸå¤±å‡½æ•°ç±»å‹")
    parser.add_argument("--focal_gamma", type=float, default=2.0, 
                       help="Focal Lossçš„gammaå‚æ•°ï¼Œæ§åˆ¶éš¾åˆ†æ ·æœ¬çš„å…³æ³¨åº¦")
    parser.add_argument("--negative_weight_boost", type=float, default=1.5, 
                       help="æ¶ˆæç±»åˆ«æƒé‡å¢å¼ºå€æ•°ï¼Œç”¨äºè¿›ä¸€æ­¥ç¼“è§£ç±»åˆ«ä¸å¹³è¡¡")
    
    # ä¿å­˜ç›¸å…³å‚æ•°
    parser.add_argument("--save_path", type=str, default="checkpoints", 
                       help="æ¨¡å‹ä¿å­˜è·¯å¾„")
    
    args = parser.parse_args()

    # ======================================================================
    # æ•°æ®åŠ è½½
    # ======================================================================
    print("æ­£åœ¨åŠ è½½æ•°æ®...")
    train_loader, val_loader, test_loader, vocab = get_dataloaders(
        args.data_dir, args.batch_size, args.max_len
    )
    
    # æ‰“å°æ•°æ®é›†ä¿¡æ¯
    print(f"è®­ç»ƒé›†å¤§å°: {len(train_loader.dataset)}")
    print(f"éªŒè¯é›†å¤§å°: {len(val_loader.dataset)}")
    print(f"æµ‹è¯•é›†å¤§å°: {len(test_loader.dataset)}")
    print(f"è¯æ±‡è¡¨å¤§å°: {len(vocab)}")
    print(f"æœ€å¤§åºåˆ—é•¿åº¦: {args.max_len}")
    
    # åˆ›å»ºæ¨¡å‹ä¿å­˜ç›®å½•
    Path(args.save_path).mkdir(parents=True, exist_ok=True)

    # ======================================================================
    # æ¨¡å‹åˆå§‹åŒ–
    # ======================================================================
    print(f"æ­£åœ¨åˆå§‹åŒ–{args.model.upper()}æ¨¡å‹...")
    
    # æ ¹æ®å‘½ä»¤è¡Œå‚æ•°é€‰æ‹©æ¨¡å‹ç±»
    if args.model == "lstm":
        model_cls = BiLSTMClassifier
    elif args.model == "gru":
        model_cls = BiGRUClassifier
    else:
        model_cls = TextCNNClassifier
    
    # åˆ›å»ºæ¨¡å‹å®ä¾‹å¹¶ç§»åŠ¨åˆ°è®¾å¤‡
    model = model_cls(len(vocab)).to(DEVICE)
    print(f"æ¨¡å‹å·²åˆ›å»ºï¼Œå‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")

    # ======================================================================
    # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨è®¾ç½®
    # ======================================================================
    print("æ­£åœ¨è®¾ç½®è®­ç»ƒç»„ä»¶...")
    
    # è®¡ç®—ç±»åˆ«æƒé‡ä»¥è§£å†³æ•°æ®ä¸å¹³è¡¡é—®é¢˜
    from sklearn.utils.class_weight import compute_class_weight
    import numpy as np
    
    print("æ­£åœ¨è®¡ç®—ç±»åˆ«æƒé‡...")
    all_labels = []
    for _, labels in train_loader:
        all_labels.extend(labels.tolist())
    
    # ä½¿ç”¨sklearnè®¡ç®—å¹³è¡¡æƒé‡
    class_weights = compute_class_weight(
        'balanced',
        classes=np.unique(all_labels),
        y=all_labels
    )
    class_weights = torch.FloatTensor(class_weights).to(DEVICE)
    
    # å¢å¼ºæ¶ˆæç±»åˆ«æƒé‡ï¼ˆç»™æ¶ˆæç±»åˆ«æ›´é«˜çš„æƒé‡ï¼‰
    negative_boost = getattr(args, 'negative_weight_boost', 1.5)  # é»˜è®¤1.5å€
    class_weights[0] *= negative_boost  # æ¶ˆæç±»åˆ«æƒé‡å¢å¼º
    
    print(f"åŸå§‹ç±»åˆ«æƒé‡è®¡ç®—å®Œæˆ")
    print(f"å¢å¼ºåç±»åˆ«æƒé‡ - æ¶ˆæ: {class_weights[0]:.4f}, ç§¯æ: {class_weights[1]:.4f}")
    print(f"æ¶ˆæç±»åˆ«æƒé‡å¢å¼ºå€æ•°: {negative_boost}")
    
    # æ ¹æ®å‚æ•°é€‰æ‹©æŸå¤±å‡½æ•°
    loss_type = getattr(args, 'loss_type', 'crossentropy')  # é»˜è®¤äº¤å‰ç†µ
    
    if loss_type == 'focal':
        # ä½¿ç”¨Focal Loss
        focal_gamma = getattr(args, 'focal_gamma', 2.0)  # é»˜è®¤gamma=2.0
        criterion = FocalLoss(alpha=class_weights, gamma=focal_gamma)
        print(f"ä½¿ç”¨Focal Loss - gamma: {focal_gamma}, alphaæƒé‡å·²åº”ç”¨")
    else:
        # ä½¿ç”¨å¸¦æƒé‡çš„äº¤å‰ç†µæŸå¤±
        criterion = nn.CrossEntropyLoss(weight=class_weights)
        print(f"ä½¿ç”¨åŠ æƒäº¤å‰ç†µæŸå¤±")
    
    # åˆå§‹åŒ–ä¼˜åŒ–å™¨ï¼ˆAdam + L2æ­£åˆ™åŒ–ï¼‰
    optimizer = optim.Adam(
        model.parameters(), 
        lr=args.lr, 
        weight_decay=args.weight_decay
    )
    
    # åˆå§‹åŒ–å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆå½“F1ä¸æå‡æ—¶é™ä½å­¦ä¹ ç‡ï¼‰
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, 
        mode='max',      # ç›‘æ§æŒ‡æ ‡è¶Šå¤§è¶Šå¥½
        factor=0.5,      # å­¦ä¹ ç‡è¡°å‡å› å­
        patience=2,      # ç­‰å¾…è½®æ•°
        verbose=True     # æ‰“å°è°ƒæ•´ä¿¡æ¯
    )
    
    # ======================================================================
    # æ£€æŸ¥å·²æœ‰æ¨¡å‹å¹¶è®¾ç½®åŸºå‡†
    # ======================================================================
    best_f1 = 0.0
    best_epoch = 0
    no_improve_count = 0
    improvement_threshold = args.min_improvement  # F1æ”¹å–„çš„æœ€å°é˜ˆå€¼
    
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å·²æœ‰çš„æœ€ä½³æ¨¡å‹
    existing_model_path = Path(args.save_path) / f"best_{args.model}.pt"
    if existing_model_path.exists():
        try:
            print(f"å‘ç°å·²æœ‰æ¨¡å‹: {existing_model_path}")
            existing_ckpt = torch.load(existing_model_path, map_location=DEVICE)
            existing_f1 = existing_ckpt.get("best_f1", 0.0)
            existing_epoch = existing_ckpt.get("epoch", 0)
            
            print(f"å·²æœ‰æ¨¡å‹æœ€ä½³F1: {existing_f1:.6f} (ç¬¬{existing_epoch}è½®)")
            
            # æ ¹æ®å‘½ä»¤è¡Œå‚æ•°å†³å®šæ˜¯å¦ç»§ç»­è®­ç»ƒ
            if args.overwrite:
                print("âœ“ ä½¿ç”¨ --overwrite å‚æ•°ï¼Œå°†ä»0å¼€å§‹è®¡ç®—ï¼Œæ–°è®­ç»ƒçš„æ¨¡å‹å°†è¦†ç›–å·²æœ‰æ¨¡å‹")
            elif args.resume_best:
                best_f1 = existing_f1
                best_epoch = existing_epoch
                print(f"âœ“ ä½¿ç”¨ --resume_best å‚æ•°ï¼Œå°†ä½¿ç”¨å·²æœ‰æ¨¡å‹F1åˆ†æ•° {best_f1:.6f} ä½œä¸ºåŸºå‡†")
                print("  åªæœ‰è¶…è¿‡æ­¤åˆ†æ•°çš„æ¨¡å‹æ‰ä¼šè¢«ä¿å­˜")
            else:
                # äº¤äº’å¼è¯¢é—®
                response = input("æ˜¯å¦åŸºäºå·²æœ‰æ¨¡å‹çš„F1åˆ†æ•°ä½œä¸ºåŸºå‡†ç»§ç»­è®­ç»ƒï¼Ÿ(y/nï¼Œé»˜è®¤n): ").strip().lower()
                if response in ['y', 'yes', 'æ˜¯']:
                    best_f1 = existing_f1
                    best_epoch = existing_epoch
                    print(f"âœ“ å°†ä½¿ç”¨å·²æœ‰æ¨¡å‹F1åˆ†æ•° {best_f1:.6f} ä½œä¸ºåŸºå‡†")
                    print("  åªæœ‰è¶…è¿‡æ­¤åˆ†æ•°çš„æ¨¡å‹æ‰ä¼šè¢«ä¿å­˜")
                else:
                    print("âœ“ å°†ä»0å¼€å§‹è®¡ç®—ï¼Œæ–°è®­ç»ƒçš„æ¨¡å‹å°†è¦†ç›–å·²æœ‰æ¨¡å‹")
        except Exception as e:
            print(f"âš ï¸  è¯»å–å·²æœ‰æ¨¡å‹å¤±è´¥: {e}")
            print("å°†ä»0å¼€å§‹è®­ç»ƒ")
    else:
        print("æœªå‘ç°å·²æœ‰æ¨¡å‹ï¼Œå°†ä»å¤´å¼€å§‹è®­ç»ƒ")
    
    print(f"\nè®­ç»ƒè®¾ç½®å®Œæˆ - å­¦ä¹ ç‡: {args.lr}, æƒé‡è¡°å‡: {args.weight_decay}")
    print(f"æ—©åœè®¾ç½® - è€å¿ƒå€¼: {args.patience}, F1æ”¹å–„é˜ˆå€¼: {improvement_threshold}")
    print(f"å½“å‰åŸºå‡†F1: {best_f1:.6f}")
    if args.patience == 0:
        print("âš ï¸  æ—©åœå·²ç¦ç”¨ (patience=0)")
    print("="*60)
    
    # ======================================================================
    # è®­ç»ƒå¾ªç¯
    # ======================================================================
    print("å¼€å§‹è®­ç»ƒ...")
    
    for epoch in range(1, args.epochs + 1):
        # è®­ç»ƒä¸€ä¸ªepoch
        train_loss = train_one_epoch(model, train_loader, criterion, optimizer)
        
        # åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
        val_metrics = evaluate(model, val_loader, criterion)
        
        # æ‰“å°è®­ç»ƒè¿›åº¦
        print(
            f"Epoch {epoch:2d}/{args.epochs}: "
            f"train_loss={train_loss:.4f}, val_loss={val_metrics['loss']:.4f}, "
            f"val_acc={val_metrics['accuracy']:.4f}, val_f1={val_metrics['f1']:.4f}, "
            f"lr={optimizer.param_groups[0]['lr']:.6f}"
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦ï¼ˆåŸºäºéªŒè¯F1åˆ†æ•°ï¼‰
        scheduler.step(val_metrics['f1'])
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ˜¾è‘—æ”¹å–„ï¼ˆä½¿ç”¨é˜ˆå€¼é¿å…æµ®ç‚¹æ•°ç²¾åº¦é—®é¢˜ï¼‰
        current_f1 = val_metrics["f1"]
        f1_improvement = current_f1 - best_f1
        
        print(f"  å½“å‰F1: {current_f1:.6f}, æœ€ä½³F1: {best_f1:.6f}, æ”¹å–„: {f1_improvement:.6f}")
        
        if f1_improvement > improvement_threshold:
            print(f"  âœ“ éªŒè¯F1æ˜¾è‘—æå‡: {best_f1:.6f} -> {current_f1:.6f} (æ”¹å–„ {f1_improvement:.6f})")
            best_f1 = current_f1
            best_epoch = epoch
            no_improve_count = 0
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            val_attention = val_metrics.pop("attention_weights")
            torch.save(
                {
                    "model_state": model.state_dict(),
                    "vocab": vocab,
                    "args": vars(args),
                    "attention_weights": val_attention,
                    "best_f1": best_f1,
                    "epoch": epoch,
                },
                Path(args.save_path) / f"best_{args.model}.pt",
            )
            print(f"  âœ“ æ¨¡å‹å·²ä¿å­˜åˆ° {args.save_path}/best_{args.model}.pt")
        else:
            no_improve_count += 1
            if f1_improvement <= 0:
                print(f"  âœ— éªŒè¯F1ä¸‹é™æˆ–æ— å˜åŒ– (æ”¹å–„: {f1_improvement:.6f})")
            else:
                print(f"  âœ— éªŒè¯F1æå‡ä¸æ˜¾è‘— (æ”¹å–„: {f1_improvement:.6f} <= é˜ˆå€¼: {improvement_threshold})")
            
            print(f"  æ—©åœè®¡æ•°: {no_improve_count}/{args.patience}")
            
            # æ—©åœæ£€æŸ¥ï¼ˆå¦‚æœpatienceä¸º0åˆ™ç¦ç”¨æ—©åœï¼‰
            if args.patience > 0 and no_improve_count >= args.patience:
                print(f"\nğŸ›‘ æ—©åœè§¦å‘ï¼è¿ç»­{args.patience}è½®éªŒè¯F1æœªæ˜¾è‘—æå‡ï¼Œè®­ç»ƒç»“æŸã€‚")
                print(f"   æœ€ä½³F1åˆ†æ•°: {best_f1:.6f} (ç¬¬{best_epoch}è½®)")
                print(f"   å½“å‰F1åˆ†æ•°: {current_f1:.6f} (ç¬¬{epoch}è½®)")
                print(f"   æ€»è®­ç»ƒè½®æ•°: {epoch}/{args.epochs}")
                break
        
        print("-" * 60)

    # ======================================================================
    # æœ€ç»ˆæµ‹è¯•è¯„ä¼°
    # ======================================================================
    print("\næ­£åœ¨åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œæµ‹è¯•...")
    
    # åŠ è½½æœ€ä½³æ¨¡å‹
    ckpt_path = Path(args.save_path) / f"best_{args.model}.pt"
    ckpt = torch.load(ckpt_path, map_location=DEVICE)
    model.load_state_dict(ckpt["model_state"])
    
    # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
    test_metrics = evaluate(model, test_loader, criterion)
    
    print("="*60)
    print("æœ€ç»ˆæµ‹è¯•ç»“æœ:")
    print(f"  æµ‹è¯•æŸå¤±: {test_metrics['loss']:.4f}")
    print(f"  æµ‹è¯•å‡†ç¡®ç‡: {test_metrics['accuracy']:.4f}")
    print(f"  æµ‹è¯•F1åˆ†æ•°: {test_metrics['f1']:.4f}")
    print(f"  æµ‹è¯•ç²¾ç¡®ç‡: {test_metrics['precision']:.4f}")
    print(f"  æµ‹è¯•å¬å›ç‡: {test_metrics['recall']:.4f}")
    print(f"\næœ€ä½³æ¨¡å‹ä¿å­˜åœ¨: {ckpt_path}")
    print(f"è®­ç»ƒå®Œæˆäºç¬¬{ckpt['epoch']}è½®ï¼Œæœ€ä½³éªŒè¯F1: {ckpt['best_f1']:.4f}")
    print("="*60)


if __name__ == "__main__":
    main()
